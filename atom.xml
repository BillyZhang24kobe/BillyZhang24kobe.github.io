<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://billyzhang24kobe.github.io</id>
    <title>Billy Zhang</title>
    <updated>2020-07-14T07:05:17.027Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://billyzhang24kobe.github.io"/>
    <link rel="self" href="https://billyzhang24kobe.github.io/atom.xml"/>
    <subtitle>欢迎来到Billy Zhang的博客主页</subtitle>
    <logo>https://billyzhang24kobe.github.io/images/avatar.png</logo>
    <icon>https://billyzhang24kobe.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Billy Zhang</rights>
    <entry>
        <title type="html"><![CDATA[总结《Generating Hierarchical Explaination on Text Classification via Feature Interaction Detection》]]></title>
        <id>https://billyzhang24kobe.github.io/post/zong-jie-lesslessgenerating-hierarchical-explaination-on-text-classification-via-feature-interaction-detectiongreatergreater/</id>
        <link href="https://billyzhang24kobe.github.io/post/zong-jie-lesslessgenerating-hierarchical-explaination-on-text-classification-via-feature-interaction-detectiongreatergreater/">
        </link>
        <updated>2020-07-14T06:40:32.000Z</updated>
        <content type="html"><![CDATA[<h3 id="文章内容简介">文章内容简介</h3>
<p>深度学习的兴起被认为是人工智能崛起的第三次浪潮，它极大程度上推动了很多人工智能子领域的研究和进展，如：计算机视觉，自然语言处理等。然而，由于深度学习网络的架构非常的复杂，很多时候我们将其视为“Black Box（黑箱子）”。在一些任务中（如：文本分类，文本生成，图像识别等），我们已经能够训练出有着极高性能和准确度的模型。但是与此同时，这些优质模型的可解释性，一直是很多研究人员想要深入探索和学习的方向。因为只有当模型的结果具备良好的可解释性，我们才能充分地有理由依赖和信任模型的表现。</p>
<p>本文主要探究了在NLP中的文本分类模型的可解释性问题，通过识别不同输入特征（如：单词和短语）之间的联系(Feature Interaction Detection)，建立了层次化的解释(hierarchical explaination)，以此来观测输入特征中的词和短语是如何在不同层级上进行关联的。这种层级式的可视化能够帮助用户和研究者更加清晰地理解“黑箱”模型的决策（如在文本分类任务中对于不同类别的预测）。这篇文章中作者提出的通过生成Hierarchincal Explaination的方法，为模型可解释性的研究方向提供的强有力的实践支撑，能够有效促进该研究方向的进一步探索。</p>
<h3 id="文章内容描述">文章内容描述</h3>
<p>本文作者以文本分类（具体来说是情感分类）为研究的主要背景，探究了如何通过识别输入特征（词语或短语）之间的关联，来解释分类器的最终表现和行为。具体来说，作者提出了一个&quot;model-agnostic（与模型无关）&quot; 的方法 -- HEDGE (Hierarchical Explaination via Divisive Generation)，通过递归地识别文本中特征词之间最弱的(weakest) 交互，然后基于此交互不断地把长文本片段分割成若干的小文本片段，构建了层级化的解释结构。如下图例子所示，HEDGE在输入的句子&quot;a waste of good performance&quot; 的基础上，生成了层级化的解释结构，并且能够在不同的层级中看出特征之间是如何进行交互的。<br>
<img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2-1.jpg" alt="" loading="lazy"></p>
<p>下面，我们对文章作者提出的方法进行进一步解读。</p>
<ul>
<li>算法层面: 作者提出了如何构建层次化解释(Hierarchical Explaination)。该算法的具体流程如下图所示。首先，输入部分(Input)的文本 x 由 n 个单词组成，同时y^代表某个模型输出的预测label。接下来，对于一个文本序列 x，我们可以将其划分成 P 个子文本序列（注：每个子文本序列彼此独立且无交集）。紧接着，HEDGE 可以对每一个子文本序列进行操作：
<ul>
<li>找到分隔点 j；</li>
<li>按照 j 对每个子文本序列进行分割。这样一来，每个子文本序列可以被进一步划分成两个更小的子文本序列；</li>
<li>对得到的更小的子文本序列，评估其对于模型预测结果y^的贡献程度和影响(contributions)。</li>
</ul>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2-2.jpg" alt="" loading="lazy"><br>
由此算法可以看到，对于一个输入的文本序列，层级化的解释结构是通过一个自顶向下的过程来搭建的。在这个过程中，我们要回答两个问题：1）在下一个timestep，我们应该选择哪一个分割出来的文本子序列并且以此做下一步的分割？2）我们应该如何选择分隔点 j？幸运的是，这两个问题都可以通过下面的式子1来解决。这里的<img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2-4.jpg" alt="Alt" loading="lazy">表示的是两个子文本序列之间的交互分数 (interaction score)<br>
<img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2-3.jpg" alt="" loading="lazy"></p>
<p>因为我们只聚焦探讨文章作者的核心算法和思路，具体的关于该分数的计算流程请参考原文章，这里我们不做过多赘述。从式子1中我们可以看出，内层的优化目标能够帮助我们找到合适的分割点 j，外层的优化目标则能帮助我们找到在下一个timestep 选择分割的子文本序列。同时需要注意的是，当我们每次完成步骤6和7（Algorithm1）之后，我们要把生成的 P 加入到层级表示 H 中，这样每次生成的层级都能够得到保存。算法1当中，每次迭代（步骤5-9）的最后一个步骤，就是评估新得到的子文本序列对于模型预测结果的贡献，然后更新贡献集合C。具体来说，作者定义出了一个可以量化每个特征（词或短语）对于模型预测结果的贡献度的式子（见式子5）。对于该式子的解读请参照原文section 3.3。到此，在进行完所有的迭代之后，算法1能够输出两个结果：1）贡献集合C_n-1: 包含了在每一个timestep生成的子文本序列和他们的贡献分数(importance scores)；2）层级H：包含每一个timestep 对于输入文本 x 的分割。基于这两个输出结果，一个完整的层级化解释结构就能通过可视化显现出来了。<br>
<img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2-5.jpg" alt="" loading="lazy"></p>
<p>接下来，让我们一起看看作者得到的实验结果。为了展示不同模型在文本分类任务中的表现，作者挑选了三个典型的神经网络模型：LSTM，CNN 和 BERT 模型。特别地，文章用到了两个经典的数据集：<a href="https://www.researchgate.net/publication/284039049_Recursive_deep_models_for_semantic_compositionality_over_a_sentiment_treebank">SST</a> 和 <a href="https://www.researchgate.net/publication/220873867_Learning_Word_Vectors_for_Sentiment_Analysis">IMDB</a>。Table 1 显示了这三个模型在不同数据集上的分类准确度。得到了初步的分类结果之后，作者对此分别进行了定量和定性的分析。</p>
<ul>
<li>定量分析<br>
作者用了两个评价指标来衡量word-level 的解释：AOPC (Area Over the Perturbation Curve) 和 log-odds 分数。具体来说，AOPC越大，解释性越好；log-odds 分数越小，解释性越好。除此之外，作者还单独定义了另外的评价指标：cohesion-score，以此来评估给定子文本序列中词与词之间的交互程度。具体的分析结果如 Table 2 所示。可以看出，HEDGE 相比其他的方法要更能解释不同模型在两个数据集上的表现。<br>
<img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2-6.jpg" alt="" loading="lazy"><br>
<img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2-7.jpg" alt="" loading="lazy"></li>
<li>定性分析<br>
作者对于结果的定性分析主要体现在 HEDGE 相比于其他的方法，更能在词/短语层面以及它们之间的关联来进行对模型预测结果的解释。更多的对于定性分析的例子，请参照原文的附录部分.</li>
</ul>
<p>从结果中，我们能够看出，HEDGE 不论是从定量还是定性的分析中，都能显现出非常有效的对于文本分类模型预测行为的解释能力。</p>
<h3 id="自己的想法">自己的想法</h3>
<p>总体上看，这篇文章的重要贡献主要体现在以下方面：</p>
<ul>
<li>提出了一个自顶向下的可以通过识别特征交互，来创建层级化解释架构的方法。该方法能够对模型在任务中的表现提供合理有效的解释；</li>
<li>提出了一个简单且有效的能够定量特征对于模型结果的贡献的计分方法；</li>
</ul>
<p>在行业和工业界，我觉得这篇文章能够给在探究模型可解释性的方向上提供很好的思路和启发。虽然在业界，很多时候算法工程师们不会过多地关注模型的可解释性，毕竟只要训练出来的模型能够在测试中拿到很好的成绩，就已经能够证明该模型的能力和表现，不会再深究为什么模型表现得那么好。但是反过来，一旦我们的模型表现没有达到预期，如果不对模型表现的可解释性进行探究，我们很难在现有的基础上对模型进行改进。所以我觉得，这篇文章很好的说明了可解释性对于理解模型的决策有着非常重要的作用。这不仅表现在对模型的改进上，还能让我们加深对于模型决策的自信和依赖程度。</p>
<!-- ### 参考 -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[对《Efficient Large-Scale Multi-Modal Classification》的理解]]></title>
        <id>https://billyzhang24kobe.github.io/post/dui-lesslessefficient-large-scale-multi-modal-classificationgreatergreater-de-li-jie/</id>
        <link href="https://billyzhang24kobe.github.io/post/dui-lesslessefficient-large-scale-multi-modal-classificationgreatergreater-de-li-jie/">
        </link>
        <updated>2020-07-08T12:00:38.000Z</updated>
        <content type="html"><![CDATA[<h3 id="内容简介和引子">内容简介和引子</h3>
<p>多模态特征在自然语言处理领域的应用早在 [1] 中被提出。其中，语言信号和视觉信号是两种比较重要的模态信号，如何有效地结合这两种模态并且成功运用到NLP的任务中，是当时提出的一个非常重要的研究方向。在这之后，随着深度学习的崛起，如何在深度学习中融合多模态特征也是近几年非常受欢迎的一个领域。本篇文章主要解决的中心问题是“多模态分类”，其中涉及到了两种模态信息：文本和图像。在这个基础上，文章作者想要致力解决的一个问题是如何快速高效地将非常大规模的样本数据进行分类。值得一提的是，本文的作者是在NLP领域有着极其重要的推动作用的Tomas Mikolov，他在2013年提出了广为流传的Word2Vec 模型，为NLP的进一步发展奠定了强有力的基础。我个人认为，这篇文章提出的对于多模态信息融合的方法论，可以作为之后其他关于多模态融合的研究的强有力的理论支撑。</p>
<h3 id="文章内容详解">文章内容详解</h3>
<p>下面对整篇文章的中心内容做一个简要的概括和描述。文章所聚焦的真实场景是“文本分类”，它对于很多其他的下游任务有着举足轻重的作用，比如：样本文档获取和划分，情感和主题的分类等。随着在日常生活中越来越多的多模态信息的出现，文本信息在非文本信息的作用下得到了加强，使得以多模态为核心的文本分类任务变得越来越重要。具体来说，本文探究的是使用了神经网络的多模态分类任务。其中，作者主要对两个研究问题做了探究：1）什么是融合多模态数据的最好的方法？2）如何能高效地完成多模态数据的融合？</p>
<p>在已有的多模态融合的方法论的基础上，本文作者对比和调研了能够加速模态融合过程的方法。特别地，对于离散的文本类型模态和连续的图片或视觉类型模态，作者提出了一个非常高效且新颖的方法论：将连续型的模态特征离散化。这样一来，训练变得更加快速，并且还能最小化内存损耗，使得对更加大规模的多模态分类成为了可能。</p>
<p>接下来，我们来从方法层面理解一下作者的做法。首先，作者用到了FastText 中文本分类的方法来作为baseline模型 [2]。为了让该baseline处理连续或者离散型的输入特征，作者做了如下处理：1）使用了从ResNet [3] 中训练得到的2048维的连续型特征；2）对于更大规模的数据集（比如：FlickrTag），作者采用了512维的特征；3）对于这些连续型的特征，作者采用了离散化的方式来提升模态融合的速度。为了让模型能够处理大规模的数据量，作者尽可能地让模型变得简单和高效，同时也能在baseline的基础上得到性能的提升。特别地，作者探究了不同的模型在多模态分类任务上的表现。为了对比，作者采用了相同的目标函数（如下图所示），最小化这个负平均对数概率。其中N代表了样本个数，o是神经网络的输出，x<sub>n</sub>是多模态的输入，y<sub>n</sub>是真实类别标注。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/1.jpeg" alt="" loading="lazy"></figure>
<p>这里简单介绍一下作者在实验中对比的几个模型:</p>
<ol>
<li>
<p><strong>Baselines（只考虑单模态特征）</strong></p>
<ul>
<li><em>文本模型 FastText</em>： 只涉及到了文本特征，完全忽略了视觉信号（visual signal）；</li>
<li><em>连续型特征模型</em>：只涉及视觉信号（从ResNet中提取出的visual 特征），忽略文本特征。</li>
</ul>
</li>
<li>
<p><strong>连续型多模态模型（考虑多模态特征）</strong></p>
<ul>
<li><em>相加型</em>：直接在特征向量层面对文本和视觉特征进行对应元素的相加</li>
<li><em>最大池化型</em>：直接在特征向量层面对文本和视觉特征进行对应元素取最大值</li>
<li><em>Gated 型</em>：对两种模态分别进行sigmoid 非线性操作，以此来计算一种模态相对于另一种模态的注意力（attention）。当然，这里具体对哪一个模态进行非线性操作是作为一个超参数来选择的；</li>
<li><em>Bilinear 型</em>：用以抓取两种模态之间的任意联系。文章中作者直接加入了Gated 非线性操作，所以这个模型又叫做Bilinear-Gated。</li>
</ul>
</li>
<li>
<p><strong>离散化的多模态模型</strong></p>
<ul>
<li>
<p>为什么考虑离散化？<br>
连续型的多模态模型存在两个缺点：1）低效率的矩阵乘法； 2）在矩阵中存储大量的浮点型数据会耗费庞大的内存空间。因此，作者的解决方法是：对连续型的特征进行离散化的操作，以此将连续型的数据变成一个离散token所组成的序列。这样就能够在最基本的FastText初始阶段使用这些特殊的tokens，得到特殊的特征表示。这样就能弥补连续型多模态模型带来的缺陷。</p>
</li>
<li>
<p>如何实现连续特征离散化？<br>
作者用到了Product Quantization，具体的流程是这样的：1）把一段连续型的特征向量分成大小相同的若干子向量；2）对每一个子向量进行k-means聚类操作；3）对于每一个图像，找到图像中每一个subwords对应的最近的cluster centroids，然后把找到的centroid与子向量的索引进行结合以获取离散化的向量（具体例子参照原文）。在进行离散化操作后，我们可以得到一个特殊tokens组成的序列。在这之后，这些tokens将作为新的&quot;文本&quot;输入FastText模型。此时的神经网络输出可以用以下式子表示：其中x<sub>n</sub><sup>d</sup>是离散化的特征，alpha是一个控制权重的超参数。除此之外，作者还介绍了一个新颖的quantization 方法 -- Random Sample Product Quantization (RSPQ)，为了保证重合的语义信息不被丢失。</p>
</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/2.jpeg" alt="" loading="lazy"></figure>
</li>
</ol>
<p>在简单了解了文章作者的方法介绍之后，让我们来一起看看作者得到的结果是什么样的。</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/3.jpeg" alt="" loading="lazy"></figure>
<p>这个表统计了不同的模型在不同的数据集上的准确率。从中可以明显看出，不论哪一个数据集，基于多模态的分类模型（Continuous 和 Discretized）的准确率要远远超过传统的baselines模型（只考虑文本或者只考虑视觉特征）。由此可见，在文本分类任务中，当融合了多模态的特征之后，模型的性能往往会得到提升。</p>
<p>我们再来看作者对于模型训练速度做出的统计表（这里用到了大规模的训练集FlickrTag-1），对于连续型的多模态模型，可以注意到，Bilinear-gated 在三个数据集的准确率都是最高的。但是考虑到它的复杂度非常的高，训练时间很长，可以认为在偏好训练速度的前提下，Bilinear-Gated 模型并不是一个最佳选择。相反，一些很简单的模型（比如：相加型，最大池化型等）得到的准确度也非常的高，非常接近Bilinear-Gated模型。由此引申出的思考是：如果偏好准确率的话，可以选择Bilinear-gated 模型；如果对训练速度有要求，采用非常简单的相加型或者最大池化型模型也能带来很好地性能。同时，通过对连续型多模态模型进行离散化操作，可以将训练时间降到和FastText训练时间相仿的程度。这样带来的好处是：训练速度更快，并且准确率也能保证，达到了作者想要在大规模数据集上进行多模态分类的目标。</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/BillyZhang24kobe/PicGo/master/4.jpeg" alt="" loading="lazy"></figure>
<h3 id="关于这篇文章的个人思考和总结">关于这篇文章的个人思考和总结</h3>
<p>下面简单对这篇文章写一些自己的想法。文章的重要贡献体现在以下几个方面：1）对不同的多模态融合的方法进行比较和分析，从训练速度和模型准确率的层面对不同的方法进行了评估，以此得出了结论：用非常简单的模态融合方法（比如：相加或者最大池化）就能高效地达到非常好的模型表现；2）对连续型模态特征进行离散化处理，以此来进一步加速和简化整个模态融合过程；3）模型学习得到的离散化的特征表示能够为文本分类任务提供一定的可解释性。我个人非常喜欢作者对连续型特征的离散化处理，这样能将一些视觉特征转化为能够输入到FastText模型中的“文本特征”，这样就能充分利用FastText的高效学习的特点。同时，这样的创新能够使得在大规模数据上进行多模态分类成为可能。当然，我觉得这篇文章也存在一定的局限性：仅仅考虑了两种模态的信息（文本和视觉）。在之后的研究中也许能加入其他模态的信息（比如：音频）来辅助该分类任务。</p>
<p>总体来看，这篇文章对于工业界应该也可以提供非常多的启发。工业界可以提供非常多的数据，如何能有效地利用这些数据来帮助训练模型，一直是一个非常重要的问题。很多时候，工业界需要在准确度和速度上做出取舍，似乎是“鱼和熊掌不可兼得”的状态。但是这篇文章提供了一种很好的启发：如何能在保持相对高准确度的情况下还能快速训练模型。这需要对不同模态的特征进行观察和处理，选择最合理的模态融合方式。同时，对于分类任务，工业界也不能忽视可解释性带来的好处，这样才能在已有的模型架构基础上加以改进，达到更好的模型训练结果。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://billyzhang24kobe.github.io/post/hello-gridea/</id>
        <link href="https://billyzhang24kobe.github.io/post/hello-gridea/">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>